[
  {
    "id": "welcome-what-i-build-and-why",
    "title": "Welcome — What I Build and Why",
    "date": "2026-01-10",
    "tags": ["Intro", "Unity", "Medical Simulation", "XR", "ECS/DOTS", "Workflow Automation"],
    "excerpt": "A quick intro to what I build: medical simulation, digital twins, XR training, ECS/DOTS architecture, and workflow automation — plus what you’ll see in Updates.",
    "content": "# Welcome — What I Build and Why\n\nI’m **Md. Asafuddaula Sobahani Shounak**, a **Senior Unity Developer & Team Lead** focused on:\n\n- **Medical Simulation**\n- **Digital Twins**\n- **XR (VR/AR)** training systems\n- **ECS/DOTS** and scalable architecture\n- **Workflow automation** (authoring tools that unblock content production)\n- Shipping on real constraints (**Android**, performance, stability)\n\n## What you’ll see here\n\nThis “Updates” section is where I’ll post:\n\n- Devlogs on simulation systems and architecture\n- XR implementation lessons (Meta Quest, performance, UX)\n- Tooling approaches that scale content pipelines\n- Notes on production shipping and optimization\n\nIf you’re hiring for **Unity Lead / Simulation Engineer / XR Engineer** roles (EU / Singapore / NZ / Ireland), feel free to reach out.\n\n- Email: **shounak00@gmail.com**\n- LinkedIn: https://www.linkedin.com/in/shounak00\n"
  },
  {
    "id": "sit-cprep-devlog-scalable-medical-simulation-workflows",
    "title": "SIT CPREP Devlog — Building Scalable Medical Simulation Workflows",
    "date": "2026-01-10",
    "tags": ["Devlog", "Medical Simulation", "Authoring Tools", "Workflow Automation", "xAPI", "LRS", "NDA-safe"],
    "excerpt": "NDA-safe engineering patterns behind scalable medical simulation: scenario execution framework, authoring workflows for SMEs, and analytics via xAPI → LRS.",
    "content": "# SIT CPREP Devlog — Building Scalable Medical Simulation Workflows\n\nThis write-up is **NDA-safe** and focuses on engineering patterns rather than proprietary content.\n\n## The problem\n\nHealthcare training needs:\n\n- repeatable **scenario execution**\n- measurable performance (**assessment + analytics**)\n- content growth without engineering bottlenecks (**authoring workflows**)\n\n## My approach\n\n### 1) Scenario execution framework\nI approached scenarios like a **state machine / system graph**:\n\n- consistent entry/exit states\n- explicit triggers and conditions\n- assessment rules as data-driven modules\n- deterministic behavior where possible\n\n### 2) Authoring & workflow automation\nTo scale content production, I focused on tools that allow non-engineers to contribute:\n\n- structured templates for scenario creation\n- validation rules to prevent broken content\n- automation to reduce manual setup and QA effort\n\n### 3) Analytics-ready training\nTo support reporting and progress tracking:\n\n- key user actions emit **xAPI** statements\n- statements flow to an **LRS**\n- data feeds dashboards / LMS reporting\n\n## What I’d highlight for recruiters\n\n- **Systems architecture** for simulation execution\n- **Tooling that scales production**\n- **Telemetry/analytics integration (xAPI + LRS)**\n- A mindset that optimizes both **runtime performance** and **team workflow**\n\nIf you want a deeper technical breakdown (architecture diagram style), I can publish a follow-up post.\n"
  },

  {
  "id": "auto-docs-v2-custom-ai-models-recursive-logic",
  "title": "Auto Documentation Tool: Custom AI Models & Recursive Documentation",
  "date": "2026-01-12",
  "tags": [
    "Tooling",
    "Automation",
    "AI",
    "Workflow",
    "DotNet",
    "Productivity"
  ],
  "excerpt": "Major update to my Auto Documentation tool: users can now choose specific AI models and drop new scripts to generate documentation for the documentation tool itself.",
  "content": "# Auto Documentation Tool — Giving Developers More Control\n\nMaintaining documentation is one of the biggest overheads in Lead Development. I updated my Auto Documentation tool to transform it from a static generator into a flexible, self-documenting ecosystem.\n\n## The Problem\n\nStatic documentation tools often suffer from:\n\n- **Fixed Logic:** Being locked into a single AI model regardless of code complexity.\n- **Documentation Lag:** New scripts added to a project often sit undocumented because the tool doesn't 'know' about itself.\n- **Lack of Granularity:** Developers needing different levels of detail for simple .NET utilities vs. complex Unity systems.\n\n## My Approach\n\n### 1) Multi-Model Integration\nI decoupled the generation engine from the LLM provider. Users can now:\n\n- Select specific AI models based on the task (e.g., lightweight models for READMEs, heavy reasoning models for complex architectural logic).\n- Optimize for cost or speed depending on the project scale.\n\n### 2) Recursive Documentation (The 'Drop' Feature)\nI implemented a new workflow where the tool can now document itself. By dropping a new script into the system:\n\n- The tool analyzes the new logic.\n- It generates technical documentation for that specific script in real-time.\n- This ensures that as the tool grows, its own documentation stays updated automatically.\n\n### 3) Developer-First Workflow\nTo make this viable for production environments:\n\n- Integrated clean UI hooks for model selection.\n- Optimized the parsing engine to handle large .NET and Unity-specific syntax without context-window bottlenecks.\n\n## What I’d highlight for recruiters\n\n- **Extensible Tooling:** Building software that supports modular AI integration.\n- **Automation Mindset:** Solving the 'documentation debt' problem through recursive engineering.\n- **Full-Stack Tool Development:** Moving from simple scripts to a feature-rich developer utility.\n\nIf you're interested in how I'm using this to streamline my work at NextGen Studioz, feel free to reach out!"
  }
]
